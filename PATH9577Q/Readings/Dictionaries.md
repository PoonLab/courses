
# Gathering information with dictionaries

## What are dictionaries?
A dictionary is an extremely useful Python object.  It is a collection of key-value pairs, where a *key* is an immutable object like a string or integer, and a *value* is another object that is referred to by that key.  For example, in an English-language dictionary, the word *apple* is a key, and its associated value is a definition of apple.  In a phone book, the key would be your friend's name, and the value would be their phone number.  These examples should give you an intution that keys need to be unique.  You can't have two names in a phone book that are *exactly* the same; this would defeat the purpose of having a phone book in the first place.

A value can be any object, including mutable objects like lists.  It can even be a dictionary!  This creates an interesting data structure.  If you think of a dictionary as the root of a tree:
```
root --+-- key1 --> value1
       |
       +-- key2 --> value2
```
then setting `value2` to be another dictionary creates another level of the tree:
```
root --+-- key1 --> value1
       |
       +-- key2 --> root --+-- key3 --> value3
                           |
                           +-- key4 --> value4
```
This makes dictionaries a natural representation of tree-like (hierarchical) data.

## Building a dictionary
Try making a simple dictionary.  To initialize an empty dictionary, use curly braces like this:
```python
>>> d = {}
```
You can then add items to the dictionary using its `update` function:
```python
>>> d.update({'toast': 1, 'jam': 5})
>>> d
{'jam': 5, 'toast': 1}
```
We could also have initialized the dictionary starting with these items:
```python
>>> d = {'jam': 5, 'toast': 1}
>>> d = dict(jam=5, toast=1)  # another way to do it
```

[List comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) offer a more efficient way of building up a large dictionary in Python.  This is a technique where we create a list with a `for` loop over some iterable object.  The important thing is that your loop has to append tuples of `(key, value)` pairs to the growing list.  For example:
```python
>>> keys = ['winter', 'spring', 'fall', 'summer']
>>> lst = [(key, len(key)) for key in keys]  # list comprehension used here
>>> lst
[('winter', 6), ('spring', 6), ('fall', 4), ('summer', 6)]
>>> dict(lst)
{'spring': 6, 'summer': 6, 'fall': 4, 'winter': 6}
```
This method is particularly useful when your values are generated by a predefined function that you can call on each key, or if you want to filter keys based on some criterion:
```python
>>> lst2 = [(key, len(key)) for key in keys if key.startswith('s')]
>>> lst2
[('spring', 6), ('summer', 6)]
>>> dict(lst2)
{'spring': 6, 'summer': 6}
```

Another way to quickly construct a dictionary is with the `zip` command.  If you have two matched lists of the same length, where one list contains the keys and the other contains the values, then you can create a dictionary as follows:
```python
>>> keys = ['bear', 'fox', 'goose']
>>> values = [3, 10, 4]
>>> dict(zip(keys, values))
{'goose': 4, 'bear': 3, 'fox': 10}
```


## Performance
Dictionaries are also useful for rapidly looking up objects.  This is because of how they work - each key is converted by a [hash function]() into an index that is used to directly look up the associated value.  For example, suppose you have compiled a list of genes from one data set, and you need to check whether a particular gene is in the list.  One way to do this is to use the `in` operator to check if our list contains the gene:
```python
>>> from time import time
>>> li = list(range(int(1e6)))  # all integers from 0 to 999999
>>> t0 = time(); 89987 in li; t1 = time()
True
>>> t1-t0
0.003858804702758789  # seconds
```
That might not seem like a long time, but when you are dealing with a very large data set and you need to look things up many times, this can consume a lot of computing time.  This is because the computer is doing a linear search through the list.  It is like entering a bookstore and looking for a specific book by starting at the first shelf, taking each book off the shelf and looking at its cover until you find the one you want.  If the store has a million books, then on average the book you want will be roughly the 500,000th book you pull off the shelf.  (We're assuming that this is a really silly store that arranges its books completely at random.)

![](https://imgs.xkcd.com/comics/making_hash_browns.png)

To illustrate, here is a bit of Python code to demonstrate that we get about the same time as the `in` operator with a linear search through the list:
```python
from time import time
li = list(range(1000000))

t0 = time()  # start the clock!
for i in li:
  if i==89987:
    break  # exit the loop
t1 = time()
print(t1-t0)  # I get 0.0033576488494873047 seconds
```

Now let's accomplish the same task by converting our list into a dictionary.  We don't have any values to associate with the keys, so we just set them all to `None`.
```python
>>> di = dict([(k, None) for k in li])  # constructing from a list of key-value tuples
>>> t0 = time(); 89987 in di; t1 = time()
True
>>> t1-t0
4.291534423828125e-05  # seconds
```
This is nearly two orders of magnitude less time!

## Usage
Dictionaries are also very useful when you need to associate multiple values with the same key.  For example, suppose that you have observations for the same patients in different files, and you need to merge those records.  However, these files are not in the same order and don't even contain all the same patients.  One approach to deal with this situation is to read each file into Python and accumulate records under unique keys, where each key corresponds to a patient, and then writing out the information you want into another file.

I do this all the time when working through data from large cohort studies.  Of course it isn't the only way to go about this, and not necessarily the best way.  I think many would argue that you should build a database with a framework like SQLite instead of using a Python script to make yet another tabular data file.  However, I like working directly with the data and being able to inspect the end product as a plain text file.

There are many instances in bioinformatics where we need to be able to rapidly look things up.  For example, a dictionary is a natural choice for mediating the translation of codons to amino acids.  A very incomplete dictionary for this task would look something like this:
```python
dna_codon_table = {
  'TTT': 'F',  # phenylalanine
  'TTC': 'F',
  'TTA': 'L',  # leucine
  'TTG': 'L',
  'TCT': 'S'   # serine
}
```
As we read through codons, we can pass the codon to our dictionary as a key and then receive its associated value:
```python
>>> codon = 'TTC'
>>> dna_codon_table[codon]
'F'
```
But if we ask for a codon that is not present as a key, then we get an error:
```python
>>> dna_codon_table['AAA']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'AAA'
```
To prevent this error from interrupting your code, you can use the `get` function of the dictionary to specify a default value in the case of missing keys:
```python
>>> dna_codon_table.get('AAA', 'unknown')
'unknown'
```

You can get lists of all the keys or values in a dictionary:
```python
>>> dna_codon_table.keys()
dict_keys(['TTT', 'TTG', 'TTA', 'TTC', 'TCT'])
>>> dna_codon_table.values()
dict_values(['F', 'L', 'L', 'F', 'S'])
```
Note that as of Python 3, these are not ordinary lists but special objects.  Personally I think this is pretty annoying because we can't even index into these special objects:
```python
>>> foo = dna_codon_table.values()
>>> foo[1]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'dict_values' object does not support indexing
```
Instead, we have to cast this special object into a list:
```python
>>> bar = list(foo)
>>> bar[1]
'L'
>>> bar
['F', 'L', 'L', 'F', 'S']
```
